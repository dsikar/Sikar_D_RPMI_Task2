LiDAR

Lidar, which stands for Light Detection and Ranging, is a remote sensing method that uses light in the form of a pulsed laser to measure ranges (variable distances) to the Earth.

Radar uses radio waves to determine the range
10 Hz rotation rate



KITTI Vision Benchmark Suite

UnrealDataset dataset.
KITTI dataset



DUSD dataset

Parallel to computer hardware development, AI Machine Learning (ML) algorithms, have found applications in several fields including computer vision, where current state-of-the-art technology has surpassed human accuracy and performance for certain tasks.
Computer vision is a core part of the autonomous vehicle self-driving task, where the structure of the environment must be modelled.


We have trialed, as suggested in class (RMPI 373), reference management tools such as Mendeley and Zotero which seemed the more user friendly but still we did not fully adapt to the workflow, instead relying on our document layout bibliography file as our reference manager. We understand this situation is not ideal as reference management is expected to become quite complex, so have budgeted time to seek a permanent solution.  

We have conducted the initial literature survey using Google searches that usually led to the required publication. When we could not access an article, we used the library website and were generally able to access articles via institutional login. We obtained a number of texts for our initial literature review. A wider search is required to understand the scope of research in three key areas, Convolutional Neural Networks, Convolutional Neural Networks applied to Computer Vision, and Convolutional Neural Networks and Computer Vision applied to sequence learning, as we are ultimately analysing sequences of images. In our Gantt chart (Figure \ref{fig:gantt-chart}) We have set time aside to continue our literature survey.  

By concluding this step, we expect to have a list of conferences, publications, books and source code that will guide our work.

There are several approaches to designing self-driving cars, with respect to acquiring and using sensor data and control systems. At one end of the spectrum is the multi-sensor approach, where cameras, and sensors such as LIDAR and RADAR are used, then all data combined to be processed and generate predictions on steering angle and speed. At the other end is the "camera only" approach, where only images are used to generate a prediction. The former typified by Intel's subsidiary MobileEye, which manufactures the EyeQ5 chip, able of processing dozens of sensor data, including high-resolution cameras, radars, and LiDARs.
citation
https://www.mobileye.com/our-technology/evolution-eyeq-chip/

Then we have NVidia
We need to talk about different approaches such as Intel x NVidia, feature engineering x end-to-end, Elon Musk's problem-will-be-solved-with-computer-vision-alone
In this section we discuss stuff ]

\subsection{Convolutional Neural Networks}

% Tesla
% https://www.tesla.com/en_GB/autopilotAI
Tesla started on MobilEye EyeQ3, moved to NVIDIA DRIVE PX 2 AI, then started developing it's own Tesla-designed processors, currently the HW3 (Hardware 3).

There are a number of tasks related to autonomous-vehicle decision-making. An autonomous vehicle must be able to deal with obstacle detection, scene classification, lane recognition, path planning, motion control, pedestrian detection, traffic signage detection (including traffic lights). 



\subsection{The CNN "End-to-End" approach to self-driving}


where Likelihood $L$ is categorized according to three-point scale 
Low/Medium/High, Consequence $C$ according to five-point
scale Very Low/Low/Medium/High/Very High and Risk Impact $I$ is the product. We colour-coded the Risk Impact column with RAG grading, and provide steps to mitigate each identified risk. The table is subject to change as the project progresses.

We have created a contingency plan in case more time is needed for the literature survey, to cover any gaps in required domain knowledge. This will be at the expense of creating alternative models. We have contingency plans to cover for insufficient data, data loss, reporting delay, continued lockdown disruption, being unable to replicate our baseline model or alternative models. Overall the risks described indicate we should expect challenges. Consequently a mitigation plan has been put in place that we believe will successfully deal with the risks, at the cost of diminishing the scope, which is ambitious, of this project but should still give us enough results to complete our research.